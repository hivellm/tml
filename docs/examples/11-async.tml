// TML Example 11: Async Programming
// Demonstrates async/await and concurrent operations

mod async_example

use std::async { spawn, sleep, select }
use std::net.http { get, post, Response }
use std::time { Duration }

// ============================================
// ASYNC FUNCTIONS
// ============================================

// Async function declaration
async func fetch_user(id: U64) -> Outcome[User, HttpError] {
    let url = "https://api.example.com/users/" + id.to_string()
    let response = await get(url)
    return response.json()
}

// Await expressions
async func get_user_data(id: U64) -> Outcome[UserData, Error] {
    // await pauses until the future completes
    let user = await fetch_user(id)
    let profile = await fetch_profile(user.id)
    let settings = await fetch_settings(user.id)

    return Ok(UserData { user, profile, settings })
}

// ============================================
// CONCURRENT EXECUTION
// ============================================

async func fetch_all_parallel(ids: List[U64]) -> List[User] {
    // Spawn concurrent tasks
    var tasks = List.new()

    loop id in ids {
        let task = spawn async {
            await fetch_user(id)
        }
        tasks.push(task)
    }

    // Wait for all to complete
    var users = List.new()
    loop task in tasks {
        when await task {
            Ok(user) -> users.push(user),
            Err(_) -> {},  // Skip failed fetches
        }
    }

    return users
}

// Simpler parallel with join_all
async func fetch_all_simple(ids: List[U64]) -> List[Outcome[User, HttpError]] {
    let futures = ids.map(do(id) fetch_user(id))
    return await join_all(futures)
}

// ============================================
// SELECT (RACE MULTIPLE FUTURES)
// ============================================

async func fetch_with_timeout(id: U64) -> Outcome[User, Error] {
    // First one to complete wins
    select {
        user = fetch_user(id) -> Ok(user),
        _ = sleep(Duration.seconds(5)) -> Err(Error.Timeout),
    }
}

// Select with multiple branches
async func handle_events() {
    loop (true) {
        select {
            msg = channel.recv() -> {
                process_message(msg)
            },
            _ = shutdown_signal.recv() -> {
                println("Shutting down...")
                break
            },
            _ = sleep(Duration.seconds(60)) -> {
                println("Heartbeat")
            },
        }
    }
}

// ============================================
// CHANNELS
// ============================================

use std::sync { channel, Sender, Receiver }

async func producer_consumer_example() {
    // Create a channel
    let (tx, rx): (Sender[I32], Receiver[I32]) = channel()

    // Spawn producer
    spawn async {
        loop i in 0 to 10 {
            tx.send(i)
            await sleep(Duration.millis(100))
        }
        tx.close()
    }

    // Consumer
    loop (true) {
        when rx.recv() {
            Just(value) -> println("Received: " + value.to_string()),
            Nothing -> break,  // Channel closed
        }
    }
}

// Buffered channel
async func buffered_channel_example() {
    let (tx, rx) = channel.buffered(10)  // Buffer size 10

    // Can send up to 10 items without blocking
    loop i in 0 to 10 {
        tx.send(i)
    }
}

// ============================================
// ASYNC BEHAVIORS
// ============================================

behavior AsyncReader {
    async func read(this, buf: mut ref [U8]) -> Outcome[U64, IoError]
}

behavior AsyncWriter {
    async func write(this, data: ref [U8]) -> Outcome[U64, IoError]
    async func flush(this) -> Outcome[Unit, IoError]
}

// Implement async behavior
extend TcpStream with AsyncReader {
    async func read(this, buf: mut ref [U8]) -> Outcome[U64, IoError] {
        // ... implementation
        return Ok(buf.len())
    }
}

// ============================================
// ASYNC ITERATORS
// ============================================

async func process_stream() {
    let stream = create_async_stream()

    // Async for loop
    loop await item in stream {
        println("Item: " + item.to_string())
    }
}

// ============================================
// ERROR HANDLING IN ASYNC
// ============================================

async func robust_fetch(id: U64) -> Outcome[User, Error] {
    // Retry with backoff
    var attempts = 0
    let max_attempts = 3

    loop (attempts < max_attempts) {
        attempts += 1

        when await fetch_user(id) {
            Ok(user) -> return Ok(user),
            Err(e) -> {
                if attempts >= max_attempts then {
                    return Err(Error.MaxRetries(e))
                }
                let delay = Duration.seconds(attempts * 2)
                await sleep(delay)
            },
        }
    }
    return Err(Error.MaxRetries(Error.Unknown))
}

// ============================================
// MAIN ASYNC ENTRY POINT
// ============================================

async func main() {
    // Async main is supported
    let user = await fetch_user(1)

    when user {
        Ok(u) -> println("Got user: " + u.name),
        Err(e) -> println("Error: " + e.to_string()),
    }

    // Parallel fetches
    let users = await fetch_all_parallel([1, 2, 3, 4, 5])
    println("Fetched " + users.len().to_string() + " users")
}

// ============================================
// TYPES FOR EXAMPLES
// ============================================

type User {
    id: U64,
    name: String,
}

type Profile {
    bio: String,
}

type Settings {
    theme: String,
}

type UserData {
    user: User,
    profile: Profile,
    settings: Settings,
}

type HttpError = Timeout | NetworkError | ParseError
type Error = Timeout | MaxRetries(HttpError) | Other(String)

async func fetch_profile(id: U64) -> Outcome[Profile, Error] {
    return Ok(Profile { bio: "" })
}

async func fetch_settings(id: U64) -> Outcome[Settings, Error] {
    return Ok(Settings { theme: "dark" })
}
